{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4ON6ns18aQZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
      ],
      "metadata": {
        "id": "hwQXboZq8c_P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_AJh4Lc8fZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "# ___\n",
        "\n",
        "\n",
        "#Let's say we have got a dataset and we split them into training dataset and test test, and when we check the accuracy on a model which has been previously trained by training dataset , so while checking accuracy from training dataset, it gives high acccuracy but on the other hand when checking accuracy from test data set, it gives low accuracy it is called over-fitting and Low bias with high varaince\n",
        "\n",
        "\n",
        "#__\n",
        "\n",
        "\n",
        "#but when we get low accuracy from the training dataset as well as from test dataset then it is know as underfitting and High-Bias with High variance.\n",
        "\n",
        "\n",
        "# ___\n",
        "\n",
        "\n",
        "#their consequences are in the case of overfitting we get prediction with low accuracy and also in the case of uner-fitting but getting low accuracy in case of under-fitting is somehow understable since the model was trained well with enough data.\n",
        "\n",
        "# ___\n",
        "\n",
        "\n",
        "#they can be mitigated only in the case when we have low bias and low variance which simply means that we have high accuracy from the training as well as test dataset"
      ],
      "metadata": {
        "id": "E1mcO9tD8gP8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iE81TFyB-hy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2: How can we reduce overfitting? Explain in brief."
      ],
      "metadata": {
        "id": "wAc9ns1O-6ml"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nef5baH7-7ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "# __**__\n",
        "\n",
        "\n",
        "\n",
        "#Let's say , in one of the case while making a predictive module , we trained it and getting high accuracy when predicting from the training data but getting low accuaracy when predicitng from the test data . this is the case of overfitting but again to get the beetr case when need to a modeule where we have low bias and low variance. This is the required modeule which works fine on trainign as well as test data set"
      ],
      "metadata": {
        "id": "QA5G9q1sAe2M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRvt_817BVDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
      ],
      "metadata": {
        "id": "VODNIPN5BZ7y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGrn6DQPBbFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "# __****__\n",
        "\n",
        "\n",
        "#Now we have got a case where neiter the model has been trained well nor it works fine one training dataset.which simply signify that the model gives low accuracy on the training as well test dataset which is the case of underfititng and it is said to have high bias and high variance"
      ],
      "metadata": {
        "id": "HW9CPE6oBda8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaYAONfdCM4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4: Explain the bias-variance trade off in machine learning. What is the relationship between bias and variance, and how do they affect model performance?"
      ],
      "metadata": {
        "id": "8wC76oJMCOEo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PP16svuCUTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "# __**__\n",
        "\n",
        "\n",
        "#When we have trained the model , after that we usually get kinds of probelms two handle . The first scenario is when the model is performing well on the dataset from which it has been trainined but giving low accuracy on the test dataset .so this is the case with low bias and high variance .\n",
        "\n",
        "\n",
        " # __**__\n",
        "\n",
        "\n",
        "\n",
        "#In the other scenario , we have got the probelm where , the model is neither giving good accuracy on training dataset nor on the test dataset . this is the case with high bias and high variance."
      ],
      "metadata": {
        "id": "ggLKwH1MCgpu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNOmlNHrDqZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?"
      ],
      "metadata": {
        "id": "BsVKo7q5Dy1n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Zilm7XdD1W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "#Overfitting:\n",
        "# _**__\n",
        "\n",
        "Training performance significantly better than testing performance.\n",
        "Model fits noise in training data, capturing irrelevant patterns.\n",
        "High variance, poor generalization to new data.\n",
        "\n",
        "# __**__\n",
        "#Underfitting:\n",
        "\n",
        "Both training and testing performance are suboptimal.\n",
        "Model fails to capture underlying patterns in the data.\n",
        "High bias, lacks complexity.\n",
        "Detection methods:\n",
        "\n",
        "\n",
        "# __**__\n",
        "\n",
        "\n",
        "\n",
        "#Learning Curves:\n",
        "\n",
        "Plot training and validation performance over epochs.\n",
        "Overfitting: Divergence of curves.\n",
        "Underfitting: Stagnation of both curves.\n",
        "\n",
        "# __**__\n",
        "\n",
        "#Cross-Validation:\n",
        "\n",
        "Evaluate model performance on multiple subsets of data.\n",
        "Overfitting: Large performance variation across folds.\n",
        "Underfitting: Consistently poor performance.\n",
        "\n",
        "# __**__\n",
        "\n",
        "#Validation Set Performance:\n",
        "\n",
        "\n",
        "\n",
        "Monitor performance on a separate validation set.\n",
        "Overfitting: Sudden drop in validation performance.\n",
        "Underfitting: Low performance on both training and validation.\n",
        "\n",
        "\n",
        "# __**__\n",
        "#Model Complexity Analysis:\n",
        "\n",
        "Adjust model complexity and observe performance.\n",
        "Overfitting: Model performance improves but plateaus, then degrades.\n",
        "Underfitting: Model fails to improve with increased complexity."
      ],
      "metadata": {
        "id": "bdCYN4bOFrSR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9IzqxCj_GIkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?"
      ],
      "metadata": {
        "id": "CMErcUdxGR-j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDS9UPWTGURX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-"
      ],
      "metadata": {
        "id": "ul_zMyKKGaOq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kEcVuuPdGcLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}