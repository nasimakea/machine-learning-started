{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-fywXzy2GJx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
      ],
      "metadata": {
        "id": "kVeNSX852G4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:- in the simple linear regression , there is one independent varaible and outcome where we find the equation of best fit line by considering the cost function so that we  get minimum error but in the case multiple linear regression ,there are multiple features which determines the outcome\n",
        "\n",
        "\n",
        "\n",
        "Simple Linear Regression:\n",
        "Simple linear regression involves predicting the values of one dependent variable (Y) based on the values of one independent variable (X). The relationship between the two variables is assumed to be linear, and the model can be represented by the equation:\n",
        "\n",
        "\n",
        "Y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X+ϵ\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bnirol8O2N3D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckR3iMjx2Lcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
      ],
      "metadata": {
        "id": "zOJxn2GI3ZuO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgVj-6xo3b5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "Linearity: The relationship between the independent and dependent variables is assumed to be linear. This means that changes in the independent variable(s) are associated with constant and proportional changes in the dependent variable.\n",
        "\n",
        "Independence: The residuals (the differences between observed and predicted values) should be independent of each other. In other words, the value of the residual for one data point should not predict the value of the residual for another data point.\n",
        "\n",
        "Homoscedasticity: The variance of the residuals should be constant across all levels of the independent variable(s). This assumption implies that the spread of residuals remains roughly the same as the independent variable(s) increase."
      ],
      "metadata": {
        "id": "nFy0l2_u3qF5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y9jDyBNs3sVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
      ],
      "metadata": {
        "id": "Gc7bxQ873u3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "he intercept represents the predicted value of the dependent variable when all independent variables are zero. In practical terms, it is the value of the dependent variable when the independent variable(s) have no effect.\n",
        "\n",
        "\n",
        "The slope represents the change in the predicted value of the dependent variable for a one-unit change in the independent variable, assuming all other variables are held constant. It indicates the strength and direction of the relationship between the independent and dependent variables.\n",
        "\n",
        "(Intercept): It represents the predicted house price when the size of the house is zero. In the context of house prices, this doesn't have a practical interpretation because a house cannot have a size of zero. However, it provides the baseline value.\n",
        "\n",
        "(Slope): It represents the change in the predicted house price for a one-unit increase in the size of the house."
      ],
      "metadata": {
        "id": "LYEuoPHs4QHB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEWdqBW43wrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. Explain the concept of gradient descent. How is it used in machine learning?"
      ],
      "metadata": {
        "id": "DX-MVMfVPrxD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bMF1NHz1Pqm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "Gradient Descent is an iterative optimization algorithm used in machine learning to minimize the cost function or error of a model by adjusting its parameters. It is a first-order optimization algorithm that efficiently finds the minimum of a function.\n",
        "\n",
        "Here's a high-level explanation of the concept:\n",
        "\n",
        "Objective:\n",
        "\n",
        "In machine learning, the objective is to minimize a cost function, also known as an error or loss function. This function measures the difference between the predicted values and the actual values.\n",
        "Parameters:\n",
        "\n",
        "A machine learning model has parameters (weights and biases) that influence the output or predictions. The goal is to find the set of parameters that minimizes the cost function.\n",
        "Gradient:\n",
        "\n",
        "The gradient is a vector that points in the direction of the steepest increase of the function. In the context of machine learning, the gradient represents the direction and magnitude of the fastest increase in the cost function.\n",
        "Descent:\n",
        "\n",
        "Gradient Descent works by iteratively adjusting the parameters in the direction opposite to the gradient. This process is called \"descent\" because it moves towards the minimum of the cost function.\n",
        "Learning Rate:\n",
        "\n",
        "The learning rate is a hyperparameter that determines the size of the steps taken during each iteration of the algorithm. It is crucial for the convergence of the algorithm. A too small learning rate may result in slow convergence, while a too large one may cause overshooting the minimum.\n",
        "\n",
        "Gradient Descent is a fundamental optimization algorithm used in training machine learning models, particularly for tasks like linear regression, logistic regression, and neural network training. It allows models to learn optimal parameter values by iteratively adjusting them to minimize the error. Stochastic Gradient Descent (SGD) and Mini-batch Gradient Descent are variations that use random or mini-batch subsets of the data to make the algorithm computationally efficient, especially in large datasets."
      ],
      "metadata": {
        "id": "UZ2j5EHSQJIb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ePYu55WCQKnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
      ],
      "metadata": {
        "id": "gWPLWE_zQL_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "Multiple linear regression is an extension of simple linear regression that involves predicting the values of a dependent variable based on two or more independent variables. While simple linear regression deals with only one independent variable, multiple linear regression incorporates multiple predictors to better capture the complexity of real-world relationships.\n",
        "\n",
        "Simple linear regression can be visualized in two dimensions, where you have a scatter plot with a regression line. Multiple linear regression involves more than two dimensions, making it challenging to visualize in a graph. However, statistical tools and techniques are used to assess the relationships between multiple variables."
      ],
      "metadata": {
        "id": "s-1w84guQo0B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ts9bpbajQP-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
      ],
      "metadata": {
        "id": "tR848wqCQ1fC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0cBdm0bQ3Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "\n",
        "Multicollinearity is a phenomenon in multiple linear regression where two or more independent variables in a model are highly correlated. This correlation can lead to issues in the estimation of individual coefficients and their interpretation. Multicollinearity does not affect the predictive accuracy of the model, but it makes it challenging to identify the unique contribution of each variable."
      ],
      "metadata": {
        "id": "Sigw7aFBRFcd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45kfO8r2RG6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vj1Jmbe8RLA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. Describe the polynomial regression model. How is it different from linear regression?"
      ],
      "metadata": {
        "id": "C4CMMf89RLIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANS:-\n",
        "\n",
        "\n",
        "Polynomial regression is a type of regression analysis where the relationship between the independent variable(s) and the dependent variable is modeled as an\n",
        "�\n",
        "n-th degree polynomial. Unlike linear regression, which assumes a linear relationship between the variables, polynomial regression allows for more flexibility by fitting a curve to the data.Linear regression assumes a linear relationship between the independent and dependent variables. Polynomial regression allows for more complex, non-linear relationships by introducing higher-degree polynomial terms.\n",
        "\n",
        "Linear regression coefficients have straightforward interpretations: the change in the dependent variable for a one-unit change in the independent variable. In polynomial regression, the interpretation becomes more complex as it involves the impact of changes in higher-degree polynomial terms."
      ],
      "metadata": {
        "id": "b5i1D6l7RSJv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YqvaTT_SRlW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}