{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjgKB3QbNn1m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
      ],
      "metadata": {
        "id": "xpCffkIUNrPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNAAnctHNsB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "GridSearchCV (Cross-Validation) is a technique in machine learning used for hyperparameter tuning. Hyperparameters are external configurations for a model that are not learned from the data, such as the learning rate, number of hidden layers, or the number of trees in a random forest. The purpose of GridSearchCV is to systematically search through a predefined set of hyperparameter values, evaluating the model's performance for each combination using cross-validation, and then selecting the hyperparameters that yield the best performance."
      ],
      "metadata": {
        "id": "wdlp0b8WOJnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
        "\n",
        "# Create the SVM model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Create GridSearchCV\n",
        "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = grid_search.score(X_test, y_test)\n",
        "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM9ApoN1OLSF",
        "outputId": "298783a0-b975-4b8a-dfee-fa0941af8a9a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Test accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMus0pFzONXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?"
      ],
      "metadata": {
        "id": "kvwkM_mDPDDD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YSxMNZ_PE8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "Both Grid Search CV (Cross-Validation) and Randomized Search CV are techniques used for hyperparameter tuning in machine learning models. They help in finding the optimal set of hyperparameters for a model, which can significantly impact its performance. Here's a brief description of each and when you might choose one over the other:\n",
        "\n",
        "Grid Search CV:\n",
        "\n",
        "In Grid Search CV, you specify a grid of hyperparameter values, and the algorithm evaluates the model performance for each combination of hyperparameters using cross-validation.\n",
        "It exhaustively searches through all possible combinations of hyperparameter values.\n",
        "This method is computationally expensive, especially when the hyperparameter search space is large.\n",
        "It is suitable when you have a relatively small search space, and you want to ensure that you've explored all possible combinations thoroughly."
      ],
      "metadata": {
        "id": "As7bigMVPJjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr5GsMuePK-v",
        "outputId": "04cc6c74-ef32-4a91-def5-12c4c609faf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3zHcpp6PMx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Randomized Search CV, you specify a probability distribution for each hyperparameter, and the algorithm randomly samples a specified number of combinations to evaluate.\n",
        "It samples a fixed number of hyperparameter combinations, making it more efficient for large search spaces.\n",
        "This method might not explore all possible combinations but can provide good results with fewer evaluations.\n",
        "It is suitable when you have a large search space, and performing an exhaustive search with Grid Search would be too computationally expensive.\n",
        "Example code using RandomizedSearchCV in scikit-learn:"
      ],
      "metadata": {
        "id": "tP2J8eMZPV8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15]\n",
        "}\n",
        "\n",
        "\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist, n_iter=10, cv=5)\n",
        "random_search.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"Best hyperparameters:\", random_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksaCAXG7PWjj",
        "outputId": "209698fe-c4d9-49ef-ac39-191b68f9a492"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'n_estimators': 100, 'min_samples_split': 5, 'max_depth': 30}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "piPPTTwuPc_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
      ],
      "metadata": {
        "id": "wxc6xHQEPhan"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNj_aKCJPiLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "Data leakage in machine learning occurs when information from outside the training dataset is used to create a model, leading to an overly optimistic assessment of the model's performance. This can result in a model that performs well on the training and validation data but fails to generalize to new, unseen data. Data leakage can happen in various forms, and it's crucial to identify and prevent it to ensure the model's reliability.\n",
        "\n",
        "Example of Data Leakage in Machine Learning:"
      ],
      "metadata": {
        "id": "ExXqvLYDPpaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate a simple dataset with a feature and a target variable\n",
        "data = {'Feature': [1, 2, 3, 4, 5, 6],\n",
        "        'Target': [0, 0, 0, 1, 1, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Introduce a data leakage by using information from the target variable in the feature\n",
        "df['Leakage_Feature'] = df['Feature'] * df['Target']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate features and target variable\n",
        "X_train = train_data[['Feature', 'Leakage_Feature']]\n",
        "y_train = train_data['Target']\n",
        "X_test = test_data[['Feature', 'Leakage_Feature']]\n",
        "y_test = test_data['Target']\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUFY0EAePqkm",
        "outputId": "1ca1f1c8-7d82-49d0-c546-2e0a0719ff02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLPlPWlsPs43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. How can you prevent data leakage when building a machine learning model?"
      ],
      "metadata": {
        "id": "mJBN9kBMQckS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04HDTaOTQdoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANS:-\n",
        "\n",
        "Preventing data leakage is crucial to ensure the robustness and reliability of machine learning models. Here are some strategies to help prevent data leakage:\n",
        "\n",
        "Strict Separation of Training and Testing Data:\n",
        "\n",
        "Always maintain a clear separation between the training and testing datasets. Ensure that the model is trained only on historical data and evaluated on completely unseen data.\n",
        "Feature Engineering Awareness:\n",
        "\n",
        "Be cautious when creating new features and make sure they are derived only from information available before the target variable is observed. Avoid using future information or information that directly incorporates the target variable in the training features."
      ],
      "metadata": {
        "id": "78uORoJjQldD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRkyYGw3Qmzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
      ],
      "metadata": {
        "id": "jh5wSK3hQqG6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q1_JQ3fXQsBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2pjyIOcXQ1zU"
      }
    }
  ]
}